{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:18:39\n"
     ]
    }
   ],
   "source": [
    "basepath ='/Users/gupta/Desktop/ML-DTU-Workshop/aclImdb'\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "pbar = pyprind.ProgBar(50000)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for s in ('test', 'train'):\n",
    "    for l in ('pos', 'neg'):\n",
    "        path = os.path.join(basepath, s, l)\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path, file), 'r', encoding='utf-8') as infile:\n",
    "                txt = infile.read()\n",
    "            df = df.append([[txt, labels[l]]], ignore_index=True)\n",
    "            pbar.update()\n",
    "df.columns = ['review', 'sentiment']\n",
    "#To shuffle the data\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv('movie_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  sentiment\n",
      "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
      "1  OK... so... I really like Kris Kristofferson a...          0\n",
      "2  ***SPOILER*** Do not read this, if you think a...          0\n",
      "3  hi for all the people who have seen this wonde...          1\n",
      "4  I recently bought the DVD, forgetting just how...          0\n",
      "5  Leave it to Braik to put on a good show. Final...          1\n",
      "6  Nathan Detroit (Frank Sinatra) is the manager ...          1\n",
      "7  To understand \"Crash Course\" in the right cont...          1\n",
      "8  I've been impressed with Chavez's stance again...          1\n",
      "9  This movie is directed by Renny Harlin the fin...          1\n",
      "is seven.<br /><br />Title (Brazil): Not Available\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df = pd.read_csv('movie_data.csv')\n",
    "print(df.head(10))\n",
    "print(df.loc[0,'review'][-50:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the sun': 5, 'sun is': 4, 'is shining': 1, 'the weather': 6, 'weather is': 7, 'is sweet': 2, 'shining and': 3, 'and the': 0}\n",
      "[[0 1 0 0 1 1 0 0]\n",
      " [0 0 1 0 0 0 1 1]\n",
      " [1 1 1 1 1 1 1 1]]\n",
      "[[0.   0.58 0.   0.   0.58 0.58 0.   0.  ]\n",
      " [0.   0.   0.58 0.   0.   0.   0.58 0.58]\n",
      " [0.43 0.33 0.33 0.43 0.33 0.33 0.33 0.33]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#UNIGRAM MODEL\n",
    "count = CountVectorizer(ngram_range=(2,2))\n",
    "docs = np.array([\n",
    "        'The sun is shining',\n",
    "        'The weather is sweet',\n",
    "        'The sun is shining and the weather is sweet'])\n",
    "bag = count.fit_transform(docs)\n",
    "print(count.vocabulary_)\n",
    "print(bag.toarray())\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(tfidf.fit_transform(bag).toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is seven alsoknown as available :(\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "['runner', 'like', 'run', 'run', 'alot']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)    \n",
    "    text = re.sub('[\\W]+',' ',text.lower())+ ' '.join(emoticons).replace('-', '')\n",
    "    return text\n",
    "df['review'] = df['review'].apply(preprocessor)\n",
    "print(preprocessor('is seven also<br\\>known as :-( (Available)'))\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "stop = stopwords.words('english')\n",
    "print(list(w for w in tokenizer_porter('a runner likes running and runs alot') if w not in stop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "X_train = df.loc[:25000,'review'].values\n",
    "y_train = df.loc[:25000,'sentiment'].values\n",
    "X_test = df.loc[25000:,'review'].values\n",
    "y_test = df.loc[25000:,'sentiment'].values\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Convert raw documents into the sparse matrix\n",
    "tfidf = TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None,)\n",
    "\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                ('clf', LogisticRegression(random_state=0))])\n",
    "\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "            'vect__stop_words': [stop, None],\n",
    "            'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "            'clf__penalty': ['l1', 'l2'],\n",
    "            'clf__C': [1.0, 10.0, 100.0] },\n",
    "            {'vect__ngram_range': [(1, 1)],\n",
    "            'vect__stop_words': [stop, None],\n",
    "            'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "            'vect__use_idf':[False],\n",
    "            'vect__norm':[None],\n",
    "            'clf__penalty': ['l1', 'l2'],\n",
    "            'clf__C': [1.0, 10.0, 100.0]},\n",
    "            ]\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,scoring='accuracy',cv=5,verbose=1,n_jobs=1)\n",
    "\n",
    "gs_lr_tfidf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameter set:', gs_lr_tfidf.best_params_)\n",
    "print('CV Accuracy:',gs_lr_tfidf.best_score_)\n",
    "\n",
    "\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Test Accuracy:',clf.score(X_test, y_test))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"total time spent in hyperrparamter training \",(t2-t1)/60,\"mins\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
